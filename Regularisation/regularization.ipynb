{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regularization\n",
    "    Regularization helps to solve over fitting problem in machine learning. Simple model will be a very poor generalization of data. At the same time, complex model may not perform well in test data due to over fitting. We need to choose the right model in between simple and complex model. Regularization helps to choose preferred model complexity, so that model is better at predicting. Regularization is nothing but adding a penalty term to the objective function and control the model complexity using that penalty term. It can be used for many machine learning algorithms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Why Regularisation\n",
    "\n",
    "1. Overfitting\n",
    "2. Overfitting with linear models\n",
    "3. Regularization of linear models\n",
    "4. Regularized regression in scikit-learn\n",
    "5. Comparing regularized linear models with unregularized linear models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Overfitting\n",
    "\n",
    "**What is overfitting?**\n",
    "\n",
    "- Building a model that matches the training data \"too closely\".\n",
    "- Learning from the error/distrubance/noise in the data, rather than just the truevalues/signal.\n",
    "\n",
    "**How does overfitting occur?**\n",
    "\n",
    "- Evaluating a model by testing it on the same data that was used to train it.\n",
    "- Creating a model that is \"too complex\".\n",
    "\n",
    "**What is the impact of overfitting?**\n",
    "\n",
    "- Model will do well on the training data, but won't generalize to out-of-sample data i.e., test \n",
    "- Model will have low bias, but high variance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Overfitting with linear models\n",
    "\n",
    "**What are the general characteristics of linear models?**\n",
    "\n",
    "- Low model complexity\n",
    "- High bias, low variance\n",
    "- Generally, Does not tend to overfit\n",
    "\n",
    "there is always a chance for **overfitting and it can still occur** with linear models if you allow them to have **high variance**. <br>Some common causes are:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cause 1: Irrelevant features\n",
    "\n",
    "Linear models can overfit if we include \"irrelevant features\", meaning features that are unrelated to the response. Why?\n",
    "\n",
    "Because it will learn a coefficient for every feature you include in the model, regardless of whether that feature has the **impact** or the **noise**.\n",
    "\n",
    "This is especially a problem when **p (number of features) is close to n (number of observations)**, because that model will naturally have high variance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cause 2: Correlated features(Muticollinearity)\n",
    "\n",
    "Linear models can overfit if the included features are highly correlated with one another. Why?\n",
    "\n",
    "We use OLS(Ordinary Least Squares ) method (OLS takes some assumptions) [scikit-learn documentation](http://scikit-learn.org/stable/modules/linear_model.html#ordinary-least-squares):\n",
    "\n",
    "  #### \"...coefficient estimates for Ordinary Least Squares rely on the independence of the model terms. When terms are correlated and the columns of the design matrix X have an approximate linear dependence, the design matrix becomes close to singular and as a result, the least-squares estimate becomes highly sensitive to random errors in the observed response, producing a large variance.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cause 3: Large coefficients\n",
    "\n",
    "Linear models can overfit if the coefficients (after feature standardization) are too large. Why?\n",
    "\n",
    "Because the **larger** the absolute value of the coefficient, the more **power** it has to change the predicted response, resulting in a higher variance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Regularization of linear models\n",
    "\n",
    "- Regularization is a method for \"constraining\" or \"regularizing\" the **size of the coefficients**, thus \"shrinking\" them towards zero.\n",
    "- It reduces model variance and thus **minimizes overfitting**.\n",
    "- If the model is too complex, it tends to reduce variance more than it increases bias, resulting in a model that is **more likely to generalize**.\n",
    "\n",
    "Our aim is to locate the **optimum model complexity**, and thus regularization is useful when we believe our model is too complex."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Bias-variance tradeoff](bias_variance.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How does regularization work?\n",
    "\n",
    "For a normal linear regression model, we estimate the coefficients using the least squares criterion, which **minimizes the residual sum of squares (RSS):**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Estimating coefficients](estimating_coefficients.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a regularized linear regression model, we **minimize the sum of RSS and a \"penalty term\"** that penalizes coefficient size.\n",
    "\n",
    "**Ridge regression** (or \"L2 regularization\") minimizes: $$\\text{RSS} + \\alpha \\sum_{j=1}^p \\beta_j^2$$\n",
    "\n",
    "**Lasso regression** (or \"L1 regularization\") minimizes: $$\\text{RSS} + \\alpha \\sum_{j=1}^p |\\beta_j|$$\n",
    "\n",
    "- $p$ is the **number of features**\n",
    "- $\\beta_j$ is a **model coefficient**\n",
    "- $\\alpha$ is a **tuning parameter:**\n",
    "    - A tiny $\\alpha$ imposes no penalty on the coefficient size, and is equivalent to a normal linear regression model.\n",
    "    - Increasing the $\\alpha$ penalizes the coefficients and thus shrinks them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lasso and ridge path diagrams\n",
    "\n",
    "A larger alpha (towards the left of each diagram) results in more regularization:\n",
    "\n",
    "- **Lasso regression** shrinks coefficients all the way to zero, thus removing them from the model\n",
    "- **Ridge regression** shrinks coefficients toward zero, but they rarely reach zero\n",
    "\n",
    "Source code for the diagrams: [Lasso regression](http://scikit-learn.org/stable/auto_examples/linear_model/plot_lasso_lars.html) and [Ridge regression](http://scikit-learn.org/stable/auto_examples/linear_model/plot_ridge_path.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Lasso and Ridge Path Diagrams](lasso_ridge_path.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### How should we choose between Lasso regression and Ridge regression?**\n",
    "\n",
    "- Lasso regression is preferred if we believe many features are irrelevant or if we prefer a sparse model.\n",
    "- If model performance is your primary concern, it is best to try both.\n",
    "- ElasticNet regression is a combination of lasso regression and ridge Regression.\n",
    "\n",
    "**Should features be standardized?**\n",
    "\n",
    "- Yes, because otherwise, features would be penalized simply because of their scale.\n",
    "- Also, standardizing avoids penalizing the intercept, which wouldn't make intuitive sense."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing regularization\n",
    "\n",
    "Below is a visualization of what happens when you apply regularization. The general idea is that you are **restricting the allowed values of your coefficients** to a certain \"region\". **Within that region**, you want to find the coefficients that result in the best model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Lasso and Ridge Coefficient Plots](lasso_ridge_coefficients.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this diagram:\n",
    "\n",
    "- We are fitting a linear regression model with **two features**, $x_1$ and $x_2$.\n",
    "- $\\hat\\beta$ represents the set of two coefficients, $\\beta_1$ and $\\beta_2$, which minimize the RSS for the **unregularized model**.\n",
    "- Regularization restricts the allowed positions of $\\hat\\beta$ to the **blue constraint region:**\n",
    "    - For lasso, this region is a **diamond** because it constrains the absolute value of the coefficients.\n",
    "    - For ridge, this region is a **circle** because it constrains the square of the coefficients.\n",
    "- The **size of the blue region** is determined by $\\alpha$, with a smaller $\\alpha$ resulting in a larger region:\n",
    "    - When $\\alpha$ is zero, the blue region is infinitely large, and thus the coefficient sizes are not constrained.\n",
    "    - When $\\alpha$ increases, the blue region gets smaller and smaller.\n",
    "\n",
    "In this case, $\\hat\\beta$ is **not** within the blue constraint region. Thus, we need to **move $\\hat\\beta$ until it intersects the blue region**, while **increasing the RSS as little as possible.**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Regularized regression in scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Communities and Crime dataset from the UCI Machine Learning Repository: [data](http://archive.ics.uci.edu/ml/machine-learning-databases/communities/communities.data), [data dictionary](http://archive.ics.uci.edu/ml/datasets/Communities+and+Crime)\n",
    "- **Goal:** Predict the violent crime rate for a community given socioeconomic and law enforcement data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and prepare the crime dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing necessary packages and functions required\n",
    "import numpy as np # for numerical computations\n",
    "import pandas as pd # for data processing,I/O file operations\n",
    "import matplotlib.pyplot as plt # for visualization of different kinds of plots\n",
    "%matplotlib inline\n",
    "# for matplotlib graphs to be included in the notebook, next to the code\n",
    "import seaborn as sns # for visualization\n",
    "import warnings # to silence warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>118</th>\n",
       "      <th>119</th>\n",
       "      <th>120</th>\n",
       "      <th>121</th>\n",
       "      <th>122</th>\n",
       "      <th>123</th>\n",
       "      <th>124</th>\n",
       "      <th>125</th>\n",
       "      <th>126</th>\n",
       "      <th>127</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Lakewoodcity</td>\n",
       "      <td>1</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.12</td>\n",
       "      <td>...</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>53</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Tukwilacity</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.45</td>\n",
       "      <td>...</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.45</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>24</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Aberdeentown</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.17</td>\n",
       "      <td>...</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>34</td>\n",
       "      <td>5.0</td>\n",
       "      <td>81440.0</td>\n",
       "      <td>Willingborotownship</td>\n",
       "      <td>1</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.77</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.12</td>\n",
       "      <td>...</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.28</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>42</td>\n",
       "      <td>95.0</td>\n",
       "      <td>6096.0</td>\n",
       "      <td>Bethlehemtownship</td>\n",
       "      <td>1</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.09</td>\n",
       "      <td>...</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.03</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 128 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0     1        2                    3    4     5     6     7     8     9    \\\n",
       "0    8   NaN      NaN         Lakewoodcity    1  0.19  0.33  0.02  0.90  0.12   \n",
       "1   53   NaN      NaN          Tukwilacity    1  0.00  0.16  0.12  0.74  0.45   \n",
       "2   24   NaN      NaN         Aberdeentown    1  0.00  0.42  0.49  0.56  0.17   \n",
       "3   34   5.0  81440.0  Willingborotownship    1  0.04  0.77  1.00  0.08  0.12   \n",
       "4   42  95.0   6096.0    Bethlehemtownship    1  0.01  0.55  0.02  0.95  0.09   \n",
       "\n",
       "   ...   118   119   120   121   122  123  124   125   126   127  \n",
       "0  ...  0.12  0.26  0.20  0.06  0.04  0.9  0.5  0.32  0.14  0.20  \n",
       "1  ...  0.02  0.12  0.45   NaN   NaN  NaN  NaN  0.00   NaN  0.67  \n",
       "2  ...  0.01  0.21  0.02   NaN   NaN  NaN  NaN  0.00   NaN  0.43  \n",
       "3  ...  0.02  0.39  0.28   NaN   NaN  NaN  NaN  0.00   NaN  0.12  \n",
       "4  ...  0.04  0.09  0.02   NaN   NaN  NaN  NaN  0.00   NaN  0.03  \n",
       "\n",
       "[5 rows x 128 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reading the dataset\n",
    "url = 'http://archive.ics.uci.edu/ml/machine-learning-databases/communities/communities.data'\n",
    "crime = pd.read_csv(url, header=None, na_values=['?'])\n",
    "crime.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    1994.000000\n",
       "mean        0.237979\n",
       "std         0.232985\n",
       "min         0.000000\n",
       "25%         0.070000\n",
       "50%         0.150000\n",
       "75%         0.330000\n",
       "max         1.000000\n",
       "Name: 127, dtype: float64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# examining the response variable\n",
    "crime[127].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x281d4275c50>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(20, 6))\n",
    "sns.heatmap(crime.isnull(),yticklabels=False,cbar=False,cmap='viridis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove categorical features\n",
    "crime.drop([0, 1, 2, 3, 4], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove rows with any missing values\n",
    "crime.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x281d442a710>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABGsAAAFuCAYAAAA23JWJAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAbXUlEQVR4nO3de5StZ10f8O/vhIDEQLgnpVyCgAItigFD0ShQCwYF5NYKtJY7trTgAkFiwUUUjYGiKBS8cFUUWYQipNwEKkGshCSEkAQCKFSSpcAKQoFAuObpH+97knFyLvPO7Jzzmzmfz1qzzj57z/7uZ579zrtnf/d7qTFGAAAAAOhh18EeAAAAAABXUdYAAAAANKKsAQAAAGhEWQMAAADQiLIGAAAAoBFlDQAAAEAj19rfN9xn1791bm8AAACAFXrXFafV3m6zZQ0AAABAI8oaAAAAgEaUNQAAAACNKGsAAAAAGlHWAAAAADSirAEAAABoRFkDAAAA0IiyBgAAAKARZQ0AAABAI8oaAAAAgEaUNQAAAACNKGsAAAAAGlHWAAAAADSirAEAAABoRFkDAAAA0IiyBgAAAKARZQ0AAABAI8oaAAAAgEaUNQAAAACNKGsAAAAAGlHWAAAAADSirAEAAABoRFkDAAAA0IiyBgAAAKARZQ0AAABAI8oaAAAAgEaUNQAAAACNKGsAAAAAGlHWAAAAADSirAEAAABoRFkDAAAA0IiyBgAAAKARZQ0AAABAI8oaAAAAgEaUNQAAAACNKGsAAAAAGlHWAAAAADSirAEAAABoRFkDAAAA0IiyBgAAAKARZQ0AAABAI8oaAAAAgEaUNQAAAACNKGsAAAAAGlHWAAAAADSirAEAAABoRFkDAAAA0IiyBgAAAKARZQ0AAABAI8oaAAAAgEaUNQAAAACNKGsAAAAAGlHWAAAAADSirAEAAABoRFkDAAAA0IiyBgAAAKARZQ0AAABAI8oaAAAAgEaUNQAAAACNKGsAAAAAGlHWAAAAADSirAEAAABoRFkDAAAA0IiyBgAAAKARZQ0AAABAI8oaAAAAgEaUNQAAAACNKGsAAAAAGlHWAAAAADSirAEAAABoRFkDAAAA0IiyBgAAAKARZQ0AAABAI8oaAAAAgEaUNQAAAACNKGsAAAAAGlHWAAAAADSirAEAAABoRFkDAAAA0IiyBgAAAKARZQ0AAABAI8oaAAAAgEaUNQAAAACNKGsAAAAAGlHWAAAAADSirAEAAABoRFkDAAAA0IiyBgAAAKARZQ0AAABAI8oaAAAAgEaUNQAAAACNKGsAAAAAGlHWAAAAADSirAEAAABoRFkDAAAA0IiyBgAAAKARZQ0AAABAI8oaAAAAgEaUNQAAAACNKGsAAAAAGlHWAAAAADSirAEAAABoRFkDAAAA0IiyBgAAAKARZQ0AAABAI8oaAAAAgEaUNQAAAACNKGsAAAAAGlHWAAAAADSirAEAAABoRFkDAAAA0IiyBgAAAKARZQ0AAABAI8oaAAAAgEaUNQAAAACNKGsAAAAAGlHWAAAAADSirAEAAABoRFkDAAAA0IiyBgAAAKARZQ0AAABAI8oaAAAAgEaUNQAAAACNKGsAAAAAGlHWAAAAADSirAEAAABoRFkDAAAA0IiyBgAAAKARZQ0AAABAI8oaAAAAgEaUNQAAAACNKGsAAAAAGlHWAAAAADSirAEAAABoRFkDAAAA0IiyBgAAAKARZQ0AAABAI8oaAAAAgEaUNQAAAACNKGsAAAAAGlHWAAAAADSirAEAAABoRFkDAAAA0IiyBgAAAKARZQ0AAABAI8oaAAAAgEaUNQAAAACNKGsAAAAAGlHWAAAAADSirAEAAABoRFkDAAAA0IiyBgAAAKARZQ0AAABAI8oaAAAAgEaUNQAAAACNKGsAAAAAGlHWAAAAADSirAEAAABoRFkDAAAA0IiyBgAAAKARZQ0AAABAI8oaAAAAgEaUNQAAAACNKGsAAAAAGlHWAAAAADSirAEAAABoRFkDAAAA0IiyBgAAAKARZQ0AAABAI8oaAAAAgEaUNQAAAACNKGsAAAAAGlHWAAAAADSirAEAAABoRFkDAAAA0IiyBgAAAKARZQ0AAABAI8oaAAAAgEaUNQAAAACNKGsAAAAAGlHWAAAAADSirAEAAABoRFkDAAAA0IiyBgAAAKARZQ0AAABAI8oaAAAAgEaUNQAAAACNKGsAAAAAGlHWAAAAADSirAEAAABoRFkDAAAA0IiyBgAAAKARZQ0AAABAI8oaAAAAgEaUNQAAAACNKGsAAAAAGlHWAAAAADSirAEAAABoRFkDAAAA0IiyBgAAAKARZQ0AAABAI8oaAAAAgEaUNQAAAACNKGsAAAAAGlHWAAAAADSirAEAAABoRFkDAAAA0IiyBgAAAKARZQ0AAABAI8oaAAAAgEaUNQAAAACNKGsAAAAAGlHWAAAAADSirAEAAABoRFkDAAAA0IiyBgAAAKARZQ0AAABAI8oaAAAAgEaUNQAAAACNKGsAAAAAGlHWAAAAADSirAEAAABoRFkDAAAA0IiyBgAAAKARZQ0AAABAI8oaAAAAgEaUNQAAAACNKGsAAAAAGlHWAAAAADSirAEAAABoRFkDAAAA0IiyBgAAAKARZQ0AAABAI8oaAAAAgEaUNQAAAACNKGsAAAAAGlHWAAAAADSirAEAAABoRFkDAAAA0IiyBgAAAKARZQ0AAABAI8oaAAAAgEaUNQAAAACNKGsAAAAAGlHWAAAAADSirAEAAABoRFkDAAAA0IiyBgAAAKARZQ0AAABAI8oaAAAAgEaUNQAAAACNKGsAAAAAGlHWAAAAADSirAEAAABoRFkDAAAA0IiyBgAAAKARZQ0AAABAI8oaAAAAgEaUNQAAAACNKGsAAAAAGlHWAAAAADSirAEAAABoRFkDAAAA0IiyBgAAAKARZQ0AAABAI8oaAAAAgEaUNQAAAACNKGsAAAAAGlHWAAAAADSirAEAAABoRFkDAAAA0IiyBgAAAKARZQ0AAABAI8oaAAAAgEaUNQAAAACNKGsAAAAAGlHWAAAAADSirAEAAABoRFkDAAAA0IiyBgAAAKARZQ0AAABAI8oaAAAAgEaUNQAAAACNKGsAAAAAGlHWAAAAADSirAEAAABoRFkDAAAA0IiyBgAAAKARZQ0AAABAI8oaAAAAgEaUNQAAAACNKGsAAAAAGlHWAAAAADSirAEAAABoRFkDAAAA0IiyBgAAAKARZQ0AAABAI8oaAAAAgEaUNQAAAACNKGsAAAAAGlHWAAAAADSirAEAAABoRFkDAAAA0IiyBgAAAKARZQ0AAABAI8oaAAAAgEaUNQAAAACNKGsAAAAAGlHWAAAAADSirAEAAABoRFkDAAAA0IiyBgAAAKARZQ0AAABAI8oaAAAAgEaUNQAAAACNKGsAAAAAGlHWAAAAADSirAEAAABoRFkDAAAA0IiyBgAAAKARZQ0AAABAI8oaAAAAgEaUNQAAAACNKGsAAAAAGlHWAAAAAHQyxlj0leSJS++zHXI6jknO9huTHM+9HM+9HM+9HM+9HM/9oZrTcUxyPPfbNWczW9Y8cRP32Q45q8ySc2ByVpklZ3vlrDJLzvbKWWWWnO2Vs8osOdsrZ5VZcrZXziqz5ByYnFVmydleOavMkhO7QQEAAAC0oqwBAAAAaGQzZc0frOixu+WsMkvOgclZZZac7ZWzyiw52ytnlVlytlfOKrPkbK+cVWbJ2V45q8ySc2ByVpklZ3vlrDJLTpKaD3QDAAAAQAN2gwIAAABoRFkDAAAA0IiyBgAAAKCRay355qo6IcnxSS4cY7xzwf2ekuTPxhiXLBzfnrJum+TBSW6Z5NtJ/ibJn44xvrTVbAAAAICDbZ9b1lTVWWsuPyHJ/0hyvSTPqaqTFjzOc5N8oKreV1VPqqqbbmawc+nze0m+K8kPJbluptLm/VV1r81kcvBU1dsXfO8xVfW7VfWSqrpxVZ1cVRdU1eur6p8tyDlxzeWjquoVVXV+Vb22qo5eOP5zq+rZc4G4aVV1ZFX9alV9pKq+VFWXVtWZVfXoreSue4wNH3m8qo6oql+sqmdU1XdV1aOr6vSqen5VHbkg5/vXXD58nqvTq+qUqjpiQc4bq+o/LHnsveTsqqrHVtVbq+rDVfXBqnrdKtcdB2Oe56xDca43vP6Yv7/VOmSbrT+27bp6VfM8Z5nrfedsp2V62dk4vC5u5TG27TI93387LddbXR5utMKxLM6qqhus6vHnvJtW1Q9W1Z23Ojd7yL7Dwu/fVVW75svXrqrjtjrf8zJ13Gbmbe26aBWq6m5V9eCqesDSudlA9rad61XM8/52gzp8zeUnJrnPGONXktw3yb9f8DifSnKLTKXNXZN8tKreUVWPqqrrLch5QpITxxi/luTfJLnTGONZSU5M8sIFOfu0nV9Yur2ozAv2nr7umuQuC6JeneSjSS5J8p4klyf5qSTvy1TgbdQpay7/ZpLPJHlAkrOT/P6CnCS5YZIbJHlPVZ1VVU+tqpsvzEiSP8n0O/ITSX4lyYuS/GySe1fVKfu641pVdaO9fN04yU8uGM+rkxyd5DZJ3prkbklekKSS/O7CnN1OTXK7THN+3Sx7zu6e5EFJLp5/rx5cVddecP/dXpHkVkl+I9My9Nb5umdX1ZM3GtJwnndn7baT5npV64+k3zqk2/pjp66rVzXPibnen27L9KrW1YnXxX3awct00my53o+PbvQbq+pHquqi+e/8u1fVu5KcU1WXVNU9ljxoVT17zeU7VdUnknywqv6uqu6+IOrzVfXuqnpcbaG4mcfw7iTvT/KBJC9PckFVvbqqjtps7jpL9jB5UKZl8O+r6qczLc8vSHJ+VT1gQc5L11w+IdPz/ZuZfral67QPVdXfVtVzq+pOC++7dkz3rKpzMq3PXpnk55K8oqrOqKpbbjZ3ne0811uf5zHGXr+SfDjTSurGSc5Zd9uH9nXfdd977rr/H57kgUn+NMmlC3IuSHKd+fINk3xwzW0XbjRn/v7j9vJ11ySfWZDzjiRPTnJSkvOTPDPTC9+Tk7x5M3OUaaXya0luneSpSd60IOf/ZlooL05y1nz/my+ZmznnzUkenalke1qSX05y+yR/mOSUBTnfSfIXmV50139dviDnQ2suX7zutvM2Oc/nbTZnD1k/muSlST47/2xPXJDz4XX/P3v+d1eSjy2c60/Ny8Dur93//+aCnPPmf2v+eWrN/8/f5HN2XpLDt5KTaau+n03ytiSXJnlVkvsuyDl/3f/PnP+9TpKLtus8HwJzveX1xx7m6KCvQ5quP3bcunpV82yut+0yveV19dp5iNfFQ2qZbrpcP20vX7+Q5AsLcs5Kcuck90jy+SQnzNcfl+T/bGGO3prkfvPl45P89YKcC5LcP1Ox9Y+Z3os8PMl1F47nzCTft2YMfzhffkKSNyzIedFevl6c5MtLluskx2Qqe7+8Zmy3zrr31wvm+T1Jjpsvf8+SnDVj+pdJfj3J32Z6z39SkmM3kXPT+fJtMh32JEnuk+Sdh/pcr2Ke93fMmqOSfDDTi8ioqmPGGJ+taVOy2s991/on3zvG+FaS05OcXlXXXZDz8iRnV9WZSX4syfOSaTO3JF9YkJNM7fp7149ttqTNPXqM8eJ5HE8aYzxvvv7FVfW4hWPa7W5jjN2fRLywqh614L5fHGM8PcnTq+pHkzwiyblVdVGmY/tsdNPfY8cYr54v/1ZVnT3GeG5VPSZTu/jfNphzUZKfG2P8zfobqmrJMYzWbgX2R+tuO2xBzs2q6mmZnvfrV1WN+bcpWzjg9hjjfUneN38SdZ8kP5Nko3P91ao6YYzxV3Pr+4U584qqWvJ79qkkPz7GuHj9DQvnOvPjj6p62+75mf8/9ne/NY6qqodkmuvrzL/3m8nZ/fhfSfKaJK+paXPGf5dphbfRxv1bVXXbMcYnq+q4JN+cc7+xcDzd5jmZ5vrBmZbhnTTXq1p/JPtehyz53V/5OqTJ+uNArKsPxjxfOQdbnOfEXO/Pqua65WviPAavi3u2U5fpf2KFy/UDs/nl+pQk/z3TcTvXW/KzHT7GuCBJqurSMcZfzeM5d+F7s/VuPsZ4+5x11sKsb40x3pLkLfP9HpCprHlJVf35GOORG8y57hjj42vG8Hvz5ZdV1VMXjOcxmUqwb+zhtkcsyMkY47NJUlUXrxnbp2veXWcTrj/GOHfO+VRVLXkvNN9tXJjkWUmeVVXHZ5rr91XVJWOMH95gzmFjjEvnyxdnKkUyxnhXVf32gvHs1Lne8jzvs6wZYxy7l5uuyHSQ3436mX08xuUbDRlj/E5Nm7XdMclvjTE+Nl9/aabyZokdXyI0+WPp5Ox9/BvexDbJm6vqyDHGZWOMtZtb3i7JxxfkvCzTJ1HJtJXQTZJcWlXHZPqUa4lPrL9ijPGdTFtbvWNBzn9O8rKq+t4kFyZ5XHJlCfmSBTm/nWmLs6v9YZrk+Qtyzlkz14/dfWVNu9Z9ZUHOezO90CbJmVV19Bjjc/Ncf35BzmXrrxhjfCHTJtFLNot+RqbNmL+eaeu+hydXzvNbFuR0m+ck+ctMWysmveb6G5leZx6RbGquT85q1h/JvtchV/td3odVrUOuqfXHY5NNrT9OzjW/rj4Y83y114dNznOS/KckLzfXe7Wqud49z9+X6ZP2zc7zqtbVyWpfF++f6W+9Tuvqrb4unpy+y/Sr0/Nvvc0u1+dm2uL+g+tvqKrHL8hZ+3z90rrblu5S9z1VdXqm5foWVXXEGONr822H7+N+660tfC9P8vokr69p16UHLcj5ZFX9cpL/neQhmZ/zqjo8y06uc3amPTf++moDrTp5QU6qatcY44rMz/t83WFZNtd3qKrzM83TsVV1wzHGF+cSYsk8J1ffkOKsJGdV1S9k2Xvqc6rqFZnm+qeTnJFMx/nKsvfBO3WutzzPuzfjPORU1cOSXLC7cVt324PGGG/aYM6vJnn+GOOyddffLsmpY4yHbTDnOeuueukYY/cLy/PHGP9xgzmvG2M8fCPfu5+c78+0JdOVLypjjE/MLyqPGGO8aEHWHZL88yQfWDtPVXXiGGPDL3TdclY8pjvOOWduMef4TC3u2TXtG3lips1r37bRjH3kfDzJlZ8objDn7kmuuIbGs5mceyT59lZz9pD7Rxv9Hd1IzrqytsWYNnG/SnLjMcbnVzWe2uQZCa/JrJ2SM/+uXjTG+HJNn2j+UpIfzLQl5Sljg2dc3EPOSZk2q99MzsfGGF+a/+g7aUXj2dTPtZcxPXOTP9tKzpApZ78518n0IdU/jDHeXVWPTPLDmT6s+4Mxb9VyILPmnIcn+fsV5KxiPNfOdAzKy8YYp21xjlZyttYV5txuzrnFVnKuoTHdMsm3NpMzl5hfGFdtzbD2tqPHGJ/bYM4Dk7x7Tamy+/rbJnnoGGPDhWZV3XPdVeeOMb5S0zE3HzbG2FAZVVVPH2O8YKOPu4+cG2TaA+BOmXY7OXUez1FJ7jjGOHODOTdK8vX1c7SJ8fxQpvecX193/bGZdj/74w3m3HrdVf8wxvhWVd0kyY+NMd64YEyPHGO8dqPfv4+cwzPtXrZ7rl85xvjO/Hp7szHGpzeYsyPnehXzfMiWNftSVY8ZY7xKztZz5j+6/kumF/67JPn5Mcab59vOHWMct8GcJyf5r11yVjympyR5UpKPbTHnOUnul+lTg3dlOgDhGZkOxv3nY4xfP8g5x2f6VHG7j+f09VcluXem/fUzxnjg1e50DebsJStJ/vXBGtMKx3PWGOP4+fITMq1L/izTQe7/1xjj1I3krDJrXc7jM60DtprTYTwfSfIDY4xv13SmnK8leUOSH5+vf8ihnLPiMX0pyVeTfDLTsftO29MbLzn5ZJLXZjrGxGZy/iTT+v6IJP8vyZFJ3pjp+aoxxoZ3Md9PVsYYj26Us+GfbYXjeUqmLYb+MtPBm89L8sVMxcSTxhhnbMecNVkPyPT3QosxAYeQseAgQofKV9Yd1EzO5nMybcJ85Hz52CTnZCojkmUHqW6V03FMc85hmf7o+nKmfSyT6SwTSw5cKGffOR9K8sdJ7pXknvO/n5kv3/NA53Qc0ypz1lw+O1cdxO67M31ysmiOVpG1g3MuWnN5/UkBlhzYc0fmrHhMH8q0C8J9M51559JMu1M8Ksn15Kws5/z532sl+VymYysk2dRB3FeStYNzLlhz3yOSnDFfvlU28XdMl5yOY8p0PNFTM33A94/z10XzdTc40Dkdx7Qm56Kt/mz7eIy378ScgzWmJNfPdFa61yR55LrbXnoo5yzZb29HqWk/tD3elOn0jHJWkJPphemyJBlj/F1V3SvJG+bNy5Yc+6ZbTscxfXtM+1F/rao+Ocb48px5eVVdIWdlOXdN8vOZDhb2jDHGeVV1+RjjvQsyVpnTcUyrytlVVTfM9Matxvzp+hjjq1W1p4MrHoisnZpz4ZqtJj9cVXcbY5xT0/EVNrwrxA7OWWXWGNP+9O9M8s55M/L7ZTq20wuS3FTOSnJ21bSbz3dnenN8VKbj710ny4/vsKqsnZqTTIXPd+b7Xi9JxhgXz8/fds7pNqbXZ9pK9V7jqgOpHpOpzDwt0zEqD2ROxzHtzrn3VnJqOuj2Hm/KglPSd8tpOqZXZdot8H8meWxVPTRTufGNJP/qUM45ZMuaTIXDT2TaBHGtSnK1gxvJ2XTOZ6vqLmOM85JkjHFZVd0/ySsznTJwu+Z0HNM366qDut1195U17aO7pIyQsw/zm4gXVtVp87+fyybWpavK6TimFf5sqzoj4SqzdmrO45P8TlU9O9OBTt9f08H2L5lvO9RzVpm1qjNkytm3V2T6hP6wTMXxaVX1qUx/IL9uQc4qs3ZqzqrO1totp+OYjh1XnXk2yZVnv3leVT12L/e5JnM6jmlVOas6c3C3nI5juu0Y46Hz5TdV1bOS/EVNx1ZaYufl7Glzm0PhK9ML1Al7ue21claWc4skx+zlth/Zrjkdx5TpNKB7uv4mSe4sZzU5e7j/T2U6uOim7r/qnI5jWuXPNucdkeQ2nbJ2Sk6mT3t/IFOhefQWHn9H5qwiK8n3bvX5lbPhrJtnOpVwMr1xeFiS4w9m1g7O+Rfzfe+wxeesVU63MWXa4uwX1657Mn3A+sxMBww+oDkdx7TCnAuT3H4vt12yXXM6jinTbmq71l33qCQfSfLpQznHAYYBAACaq2m315MynSb5ZvPVn8u09dmpY4z1W8Rfozkdx7TCnFWdObhVTscxVdXzk7xzjPHuddefmOTFY4zbH6o5yhoAAIBtrJqdPbbjmORsvzEd6jnKGgAAgG2sqi4eY9yqS07HMcnZfmM61HMO5QMMAwAAbAvV76yv7cYkZ/uNSc7eKWsAAAD663bW145jkrP9xiRnL5Q1AAAA/b0lyZFjjPPW31BVZxyEnI5jkrP9xiRnLxyzBgAAAKCRXQd7AAAAAABcRVkDAAAA0IiyBgAAAKARZQ0AAABAI8oaAAAAgEb+P03PySUDaLH9AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 1440x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(20, 6))\n",
    "sns.heatmap(crime.isnull(),yticklabels=False,cbar=False,cmap='viridis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(319, 123)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking the shape\n",
    "crime.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define X and y\n",
    "X = crime.drop(127, axis=1)\n",
    "y = crime[127]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into training and testing sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,test_size = 0.3, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# build a linear regression model\n",
    "from sklearn.linear_model import LinearRegression\n",
    "linreg = LinearRegression()\n",
    "linreg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iNTERCEPT :  0.9922125287583894\n",
      "CO-EFFICIENT :  [-3.93018330e+00  7.31324716e-01 -3.01181421e-01 -2.96634778e-01\n",
      " -1.83170801e-01  2.81575284e-01 -1.48744636e+00 -4.84695533e-01\n",
      "  1.24104896e+00 -5.32282788e-01  4.64331123e+00 -1.17079618e-01\n",
      "  1.04229108e+00  1.36950901e-01 -3.12434116e-01 -1.16489196e+00\n",
      "  5.37252913e-01  7.49655606e-01 -8.02500871e-02  8.42449509e-01\n",
      " -1.98951720e-01 -3.17193999e-01 -4.31217869e-01  1.19357660e-01\n",
      " -1.83148129e-01  2.11602690e-01 -1.57441950e-01 -1.03051105e+00\n",
      "  1.49628176e+00  1.86093900e-01 -1.12289917e+00 -1.13107576e-02\n",
      "  1.22670519e-01  1.46348876e-01 -1.64172731e-01 -3.73690589e-02\n",
      "  1.92733806e-01  4.34808503e-01  2.32870361e+00 -5.15176228e-01\n",
      "  2.64683754e+00 -5.48075999e+00  9.63873430e-01 -1.15021921e+00\n",
      " -1.15575665e+00  1.10543276e+00  2.41469970e-01 -6.32209680e-01\n",
      "  6.01741978e-01  8.37645340e-02  1.05006759e-01 -2.58807800e-01\n",
      "  5.31513493e-01 -8.57090632e-01 -3.29684470e-01  6.61114510e-01\n",
      " -5.61884511e-01  6.27806334e-01  2.79848006e+00 -3.84376383e+00\n",
      "  6.63383105e-01  2.32831180e-01  1.15525109e+00 -2.19222321e+00\n",
      " -1.92937779e+00  1.06762622e+00 -5.01393215e-01 -1.64350691e+00\n",
      "  8.32031485e-01  5.37236526e-01  4.71215083e-02  1.63071151e-01\n",
      "  1.69213367e-01  2.37904894e+00 -6.07853084e-02  8.66170663e-02\n",
      " -1.22137425e-01 -1.33214743e-02 -9.10806303e-02 -4.95926018e-01\n",
      " -3.95077878e-01  2.10098688e-01 -7.87407370e-01 -7.33504750e-02\n",
      " -5.26665903e-03  1.32948476e+00 -6.75588810e-01 -3.80850714e-02\n",
      " -2.36755772e-01 -5.33694434e-02  2.49902747e-01  1.26616251e+00\n",
      " -3.81256219e-01 -4.90756320e-02  1.34437151e-02  3.03344698e-01\n",
      " -6.62671259e-01 -4.80322445e+01 -2.79029053e-01 -1.18121012e-01\n",
      " -1.14722614e-01  1.76167904e-01  8.81716178e-02  4.85437648e+01\n",
      " -4.68216237e-02 -3.35980437e-02  2.10370431e-01  2.57465906e-01\n",
      "  1.74268864e-01 -5.58776973e-01 -2.35432646e-01  3.77183848e-03\n",
      "  3.02620708e-02  8.18559046e-02  1.21865592e-02 -1.82516177e-01\n",
      "  1.85129424e-01  5.32261788e-01  3.97216221e-03  1.24490041e-02\n",
      " -4.86500053e-02 -4.77213525e-01]\n"
     ]
    }
   ],
   "source": [
    "print (\"iNTERCEPT : \",linreg.intercept_)\n",
    "print (\"CO-EFFICIENT : \",linreg.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make predictions\n",
    "y_pred = linreg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R-Square Value 0.19704456295409056\n",
      "\n",
      "\n",
      "mean_absolute_error : 0.16725155824888352\n",
      "\n",
      "\n",
      "mean_squared_error :  0.04986345422693408\n",
      "\n",
      "\n",
      "root_mean_squared_error :  0.22330126337961922\n"
     ]
    }
   ],
   "source": [
    "# calculate R^2 value, MAE, MSE, RMSE\n",
    "\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn import metrics\n",
    "print(\"R-Square Value\",r2_score(y_test,y_pred))\n",
    "print(\"\\n\")\n",
    "print (\"mean_absolute_error :\",metrics.mean_absolute_error(y_test, y_pred))\n",
    "print(\"\\n\")\n",
    "print (\"mean_squared_error : \",metrics.mean_squared_error(y_test, y_pred))\n",
    "print(\"\\n\")\n",
    "print (\"root_mean_squared_error : \",np.sqrt(metrics.mean_squared_error(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MSE is more popular than MAE because MSE \"eliminates\" larger errors. But, RMSE is even more better than MSE because RMSE is interpretable in the \"y\" units."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ridge regression\n",
    "\n",
    "- [Ridge](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Ridge.html) documentation\n",
    "- **alpha:** must be positive, increase for more regularization\n",
    "- **normalize:** scales the features (without using StandardScaler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R-Square Value 0.19704456295863382\n",
      "\n",
      "\n",
      "mean_absolute_error : 0.16725155824816149\n",
      "\n",
      "\n",
      "mean_squared_error :  0.04986345422665194\n",
      "\n",
      "\n",
      "root_mean_squared_error :  0.2233012633789875\n"
     ]
    }
   ],
   "source": [
    "# alpha=0 is equivalent to linear regression\n",
    "from sklearn.linear_model import Ridge\n",
    "ridgereg = Ridge(alpha=0, normalize=True)\n",
    "ridgereg.fit(X_train, y_train)\n",
    "y_pred = ridgereg.predict(X_test)\n",
    "# calculate R^2 value, MAE, MSE, RMSE\n",
    "\n",
    "from sklearn import metrics\n",
    "print(\"R-Square Value\",r2_score(y_test,y_pred))\n",
    "print(\"\\n\")\n",
    "print (\"mean_absolute_error :\",metrics.mean_absolute_error(y_test, y_pred))\n",
    "print(\"\\n\")\n",
    "print (\"mean_squared_error : \",metrics.mean_squared_error(y_test, y_pred))\n",
    "print(\"\\n\")\n",
    "print (\"root_mean_squared_error : \",np.sqrt(metrics.mean_squared_error(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R-Square Value 0.5347697501566349\n",
      "\n",
      "\n",
      "mean_absolute_error : 0.12769772972161883\n",
      "\n",
      "\n",
      "mean_squared_error :  0.028890753082631383\n",
      "\n",
      "\n",
      "root_mean_squared_error :  0.16997280100837128\n"
     ]
    }
   ],
   "source": [
    "# try alpha=0.1\n",
    "ridgereg = Ridge(alpha=0.1, normalize=True)\n",
    "ridgereg.fit(X_train, y_train)\n",
    "y_pred = ridgereg.predict(X_test)\n",
    "\n",
    "# calculate R^2 value, MAE, MSE, RMSE\n",
    "\n",
    "from sklearn import metrics\n",
    "print(\"R-Square Value\",r2_score(y_test,y_pred))\n",
    "print(\"\\n\")\n",
    "print (\"mean_absolute_error :\",metrics.mean_absolute_error(y_test, y_pred))\n",
    "print(\"\\n\")\n",
    "print (\"mean_squared_error : \",metrics.mean_squared_error(y_test, y_pred))\n",
    "print(\"\\n\")\n",
    "print (\"root_mean_squared_error : \",np.sqrt(metrics.mean_squared_error(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-5.77226675e-03  2.26721774e-02  4.98857382e-02 -6.70174168e-02\n",
      " -1.83566112e-02  5.26888536e-02  1.17689929e-02 -5.72468914e-02\n",
      "  1.52761058e-03  4.29131248e-02  1.04586550e-04 -1.85621890e-02\n",
      "  5.07008262e-02 -9.63941391e-02 -1.58499805e-01 -3.28082329e-01\n",
      " -1.43015949e-02  8.97253556e-02 -1.10520025e-01  8.02961453e-02\n",
      " -2.01498712e-02  7.77242382e-03 -8.07823610e-02 -1.39148634e-01\n",
      " -1.19008810e-02  1.00148033e-01  3.61850806e-02 -9.71628046e-02\n",
      "  6.94268658e-02 -8.81688130e-02 -9.79415666e-02 -4.99145470e-03\n",
      "  1.28541873e-01 -4.15102106e-02 -1.35952164e-01  4.09752240e-02\n",
      "  7.00727085e-02 -1.86859042e-02  5.95401646e-02  6.28621417e-02\n",
      " -3.91478791e-02  8.48551263e-03  7.31545217e-02 -1.28265573e-01\n",
      " -1.22240655e-01 -7.02441332e-02 -7.10900893e-02 -6.33671556e-02\n",
      "  1.01095274e-01 -5.22454503e-02  1.15465301e-01 -7.35016006e-02\n",
      " -4.79847841e-03 -1.10878367e-01  6.49567154e-02  4.12339751e-02\n",
      " -1.06606017e-02  1.32494298e-03  1.81063822e-02 -1.85567810e-03\n",
      " -1.32904914e-02  3.94493914e-02  1.00675199e-02 -6.17632878e-03\n",
      " -6.48193614e-03  3.75746635e-02 -1.11798761e-01  3.89474904e-02\n",
      "  3.84145367e-02  2.27608462e-01  2.56008069e-02  2.07966422e-02\n",
      "  4.30938894e-02  6.63025655e-02 -1.02913734e-02  3.78084421e-02\n",
      " -1.81938584e-02  2.67122511e-02 -5.91571726e-02 -1.11215117e-02\n",
      " -1.39886745e-02 -8.38803903e-03 -1.44263720e-01  5.42415176e-02\n",
      "  2.27326417e-02  1.05911835e-01 -1.09837108e-01 -6.00233055e-02\n",
      " -9.42476546e-02  9.20602987e-02  1.52695617e-01  3.12870498e-02\n",
      " -7.89722447e-02  3.30793696e-02 -4.49652275e-02  3.73987698e-02\n",
      " -3.92834764e-02  2.44368715e-02  2.39059642e-02 -4.36748260e-03\n",
      "  7.88355114e-03  3.52470803e-02  8.66981935e-02  2.80030258e-02\n",
      " -1.27168295e-01 -1.18490708e-02  9.56179076e-03  3.26964467e-02\n",
      "  8.95863094e-02 -3.18437162e-02 -2.36547537e-02  4.67552852e-02\n",
      " -2.69161523e-03  3.60806144e-02 -4.33459917e-02 -5.49197916e-02\n",
      "  1.14859081e-01  6.18430307e-02 -9.01777227e-03  4.93420155e-02\n",
      " -7.56394250e-02 -5.68112163e-02]\n"
     ]
    }
   ],
   "source": [
    "# examing the coefficients\n",
    "print(ridgereg.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [RidgeCV](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.RidgeCV.html): ridge regression with built-in cross-validation of the alpha parameter\n",
    "- **alphas:** array of alpha values to try"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.e-02, 1.e-01, 1.e+00, 1.e+01, 1.e+02])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create an array of alpha values\n",
    "alpha_range = 10.**np.arange(-2, 3)\n",
    "alpha_range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# select the best alpha with RidgeCV\n",
    "from sklearn.linear_model import RidgeCV\n",
    "ridgeregcv = RidgeCV(alphas=alpha_range, normalize=True, scoring='neg_mean_squared_error')\n",
    "ridgeregcv.fit(X_train, y_train)\n",
    "ridgeregcv.alpha_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R-Square Value 0.5318623469518291\n",
      "\n",
      "\n",
      "mean_absolute_error : 0.13256644483823624\n",
      "\n",
      "\n",
      "mean_squared_error :  0.02907130253772373\n",
      "\n",
      "\n",
      "root_mean_squared_error :  0.17050308659295213\n"
     ]
    }
   ],
   "source": [
    "# predict method uses the best alpha value\n",
    "y_pred = ridgeregcv.predict(X_test)\n",
    "# calculate R^2 value, MAE, MSE, RMSE\n",
    "\n",
    "from sklearn import metrics\n",
    "print(\"R-Square Value\",r2_score(y_test,y_pred))\n",
    "print(\"\\n\")\n",
    "print (\"mean_absolute_error :\",metrics.mean_absolute_error(y_test, y_pred))\n",
    "print(\"\\n\")\n",
    "print (\"mean_squared_error : \",metrics.mean_squared_error(y_test, y_pred))\n",
    "print(\"\\n\")\n",
    "print (\"root_mean_squared_error : \",np.sqrt(metrics.mean_squared_error(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lasso regression\n",
    "\n",
    "- [Lasso](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Lasso.html) documentation\n",
    "- **alpha:** must be positive, increase for more regularization\n",
    "- **normalize:** scales the features (without using StandardScaler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.          0.          0.         -0.25339884  0.          0.\n",
      "  0.         -0.         -0.          0.          0.          0.\n",
      " -0.         -0.         -0.         -0.17865705  0.          0.\n",
      " -0.         -0.         -0.         -0.         -0.         -0.02230294\n",
      " -0.          0.          0.          0.          0.0998841  -0.\n",
      "  0.         -0.          0.01893786 -0.         -0.03169217  0.\n",
      "  0.         -0.          0.11479343  0.          0.          0.\n",
      "  0.         -0.16845012 -0.27294066 -0.         -0.         -0.\n",
      " -0.          0.          0.          0.          0.         -0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      " -0.          0.          0.          0.          0.          0.\n",
      "  0.         -0.          0.          0.02709397 -0.          0.\n",
      " -0.         -0.          0.          0.          0.          0.\n",
      "  0.         -0.         -0.         -0.         -0.         -0.\n",
      " -0.         -0.          0.         -0.         -0.          0.00233805\n",
      "  0.15404259  0.         -0.         -0.          0.         -0.\n",
      "  0.          0.         -0.          0.          0.          0.\n",
      "  0.03385823  0.         -0.0136048  -0.          0.          0.\n",
      "  0.01441679  0.          0.          0.         -0.          0.\n",
      " -0.         -0.          0.04851355  0.         -0.          0.0220025\n",
      " -0.          0.        ]\n"
     ]
    }
   ],
   "source": [
    "# try alpha=0.001 and examine coefficients\n",
    "from sklearn.linear_model import Lasso\n",
    "lassoreg = Lasso(alpha=0.001, normalize=True)\n",
    "lassoreg.fit(X_train, y_train)\n",
    "print(lassoreg.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.          0.          0.         -0.04214088  0.          0.\n",
      "  0.          0.          0.         -0.          0.          0.\n",
      " -0.         -0.         -0.         -0.         -0.          0.\n",
      " -0.         -0.         -0.         -0.         -0.         -0.\n",
      " -0.         -0.         -0.          0.          0.          0.\n",
      "  0.         -0.          0.         -0.         -0.          0.\n",
      "  0.         -0.          0.          0.          0.          0.\n",
      "  0.         -0.         -0.29715868 -0.         -0.         -0.\n",
      " -0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      " -0.          0.          0.          0.          0.          0.\n",
      "  0.         -0.          0.          0.         -0.          0.\n",
      " -0.         -0.          0.          0.         -0.          0.\n",
      "  0.         -0.         -0.         -0.         -0.         -0.\n",
      " -0.         -0.          0.         -0.         -0.          0.\n",
      "  0.          0.          0.         -0.          0.          0.\n",
      "  0.          0.         -0.          0.          0.          0.\n",
      "  0.          0.         -0.         -0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.         -0.          0.\n",
      " -0.          0.        ]\n"
     ]
    }
   ],
   "source": [
    "# try alpha=0.01 and examine coefficients\n",
    "lassoreg = Lasso(alpha=0.01, normalize=True)\n",
    "lassoreg.fit(X_train, y_train)\n",
    "print(lassoreg.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R-Square Value 0.3241322659149898\n",
      "\n",
      "\n",
      "mean_absolute_error : 0.16889755277533727\n",
      "\n",
      "\n",
      "mean_squared_error :  0.04197132028397072\n",
      "\n",
      "\n",
      "root_mean_squared_error :  0.20486903202770965\n"
     ]
    }
   ],
   "source": [
    "# calculate RMSE (for alpha=0.01)\n",
    "y_pred = lassoreg.predict(X_test)\n",
    "# calculate MAE, MSE, RMSE\n",
    "# calculate R^2 value, MAE, MSE, RMSE\n",
    "\n",
    "from sklearn import metrics\n",
    "print(\"R-Square Value\",r2_score(y_test,y_pred))\n",
    "print(\"\\n\")\n",
    "print (\"mean_absolute_error :\",metrics.mean_absolute_error(y_test, y_pred))\n",
    "print(\"\\n\")\n",
    "print (\"mean_squared_error : \",metrics.mean_squared_error(y_test, y_pred))\n",
    "print(\"\\n\")\n",
    "print (\"root_mean_squared_error : \",np.sqrt(metrics.mean_squared_error(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [LassoCV](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LassoCV.html): lasso regression with built-in cross-validation of the alpha parameter\n",
    "- **n_alphas:** number of alpha values (automatically chosen) to try"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha :  0.002080882923737423\n"
     ]
    }
   ],
   "source": [
    "# select the best alpha with LassoCV\n",
    "from sklearn.linear_model import LassoCV\n",
    "lassoregcv = LassoCV(n_alphas=100, normalize=True, random_state=1)\n",
    "lassoregcv.fit(X_train, y_train)\n",
    "print('alpha : ',lassoregcv.alpha_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.          0.          0.         -0.25126823  0.          0.\n",
      "  0.          0.          0.         -0.          0.          0.\n",
      " -0.         -0.         -0.         -0.11419567  0.          0.\n",
      " -0.         -0.         -0.         -0.         -0.         -0.\n",
      " -0.          0.         -0.          0.          0.10231515  0.\n",
      "  0.         -0.          0.         -0.         -0.          0.\n",
      "  0.         -0.          0.          0.          0.          0.12654959\n",
      "  0.         -0.04766931 -0.38728958 -0.         -0.         -0.\n",
      " -0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      " -0.          0.          0.          0.          0.          0.\n",
      "  0.         -0.          0.          0.         -0.          0.\n",
      " -0.         -0.          0.          0.          0.          0.\n",
      "  0.         -0.         -0.         -0.         -0.         -0.\n",
      " -0.         -0.          0.         -0.         -0.          0.\n",
      "  0.13736646  0.         -0.         -0.         -0.         -0.\n",
      "  0.          0.         -0.          0.          0.          0.\n",
      "  0.          0.         -0.         -0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.01538139  0.         -0.          0.\n",
      " -0.          0.        ]\n"
     ]
    }
   ],
   "source": [
    "# examine the coefficients\n",
    "print(lassoregcv.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R-Square Value 0.551986438475168\n",
      "\n",
      "\n",
      "mean_absolute_error : 0.13457411347964207\n",
      "\n",
      "\n",
      "mean_squared_error :  0.027821598419367693\n",
      "\n",
      "\n",
      "root_mean_squared_error :  0.16679807678557834\n"
     ]
    }
   ],
   "source": [
    "# predict method uses the best alpha value\n",
    "y_pred = lassoregcv.predict(X_test)\n",
    "# calculate R^2 value, MAE, MSE, RMSE\n",
    "\n",
    "from sklearn import metrics\n",
    "print(\"R-Square Value\",r2_score(y_test,y_pred))\n",
    "print(\"\\n\")\n",
    "print (\"mean_absolute_error :\",metrics.mean_absolute_error(y_test, y_pred))\n",
    "print(\"\\n\")\n",
    "print (\"mean_squared_error : \",metrics.mean_squared_error(y_test, y_pred))\n",
    "print(\"\\n\")\n",
    "print (\"root_mean_squared_error : \",np.sqrt(metrics.mean_squared_error(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparing regularized linear models with unregularized linear models\n",
    "\n",
    "**Advantages of regularized linear models over linear :**\n",
    "\n",
    "- Better performance\n",
    "- L1 regularization performs automatic feature selection\n",
    "- Useful for high-dimensional problems (p > n)\n",
    "\n",
    "**Disadvantages of regularized linear models over linear :**\n",
    "\n",
    "- Tuning is required\n",
    "- Feature scaling is recommended\n",
    "- Less interpretable (due to feature scaling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
