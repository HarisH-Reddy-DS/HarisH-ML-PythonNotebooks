{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    },
    "colab": {
      "name": "Binary Logistic Regression.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "symDeSQcNwNh",
        "colab_type": "text"
      },
      "source": [
        "# Binary Logistic Regression"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0jud8sp9NwNj",
        "colab_type": "text"
      },
      "source": [
        "   # Definition:\n",
        "        Logistic regression is a statistical method for analyzing a dataset in which there are one or more independent variables that determine an outcome. The outcome is measured with a dichotomous variable (in which there are only two possible outcomes).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vZvutcavNwNk",
        "colab_type": "text"
      },
      "source": [
        "# Importing DATA & Python Packages\n",
        " "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zJN2ojZ3NwNm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np \n",
        "import pandas as pd \n",
        "from sklearn import preprocessing\n",
        "import matplotlib.pyplot as plt \n",
        "import seaborn as sns\n",
        "sns.set(style=\"white\") #white background style for seaborn plots\n",
        "sns.set(style=\"whitegrid\", color_codes=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "chbT_HboNwNp",
        "colab_type": "text"
      },
      "source": [
        "I am using the HR (Human Resources) data which consists of 1470 rows and 35 features/columns/variables making a total of 51450 observations. The data consists a combination of characters and numerics. Our main objective is to find \"Attrition Rate\" so that we can identify when a new record feature comes close to attrition the algorithms warns the HR and necessary action is taken by HR"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lj_s-l6MNwNq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 438
        },
        "outputId": "b17a2b07-186b-4343-ad0d-2ff9e68ffd1b"
      },
      "source": [
        "# Read CSV HR data file into DataFrame\n",
        "hrdf = pd.read_csv(\"HRDATA.csv\")\n",
        "# Shape data\n",
        "print('The shape of our features is:', hrdf.shape)\n",
        "# Size of data\n",
        "print(\"Size\",hrdf.size)\n",
        "# preview HR data\n",
        "hrdf.head()\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-8bb6b2cd1e38>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhrdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"HRDATA.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m# Shape data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'The shape of our features is:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhrdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Size of data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Size\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mhrdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    700\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[1;32m    701\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 702\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    703\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    704\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    427\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    428\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 429\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    430\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    431\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 895\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    896\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1120\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'c'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1121\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'c'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1122\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1123\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1124\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'python'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1851\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'usecols'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1852\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1853\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1854\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1855\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] File b'HRDATA.csv' does not exist: b'HRDATA.csv'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MD4shtSnNwNv",
        "colab_type": "text"
      },
      "source": [
        "<font color=green>We need to convert all the character data into numerics i.e., converting them into categorirical data  or encoding them into numerics. I used excel as it is simpler and faster to encode. Python can also be used. </font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4hwpMtzuNwNx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Read CSV HR data file into DataFrame\n",
        "hrdf1 = pd.read_csv(\"HRDATA-1.csv\")\n",
        "# Shape data\n",
        "print('The shape of our features is:', hrdf.shape)\n",
        "# Size of data\n",
        "print(\"Size\",hrdf1.size)\n",
        "# preview HR data\n",
        "hrdf1.head()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AYEZWVBNNwN0",
        "colab_type": "text"
      },
      "source": [
        "# Data Quality & Missing Value Assessment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E3_g-EEbNwN1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# check missing values in train data\n",
        "hrdf1.isnull().sum()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AJgvCS0dNwN4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "hrdf1.describe()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BUbLPr7xNwN6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "hrdf1['EmployeeCount'].value_counts()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XAQCSCylNwN9",
        "colab_type": "text"
      },
      "source": [
        "<font color=green> We can see in EployeeCount column is filled with \"1\" hence we remove it as 1 represents one employ as attrition is done for an employee </font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Iki_B5CBNwN-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "hrdf1=hrdf1.drop(\"EmployeeCount\",axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OMwPIE7JNwOA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Now we see correlation\n",
        "hrdf1.corr()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TgEHT-mCNwOD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "hrdf1[\"StandardHours\"].value_counts()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KBQB5i5kNwOG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "hrdf1=hrdf1.drop(\"StandardHours\",axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z5hXZpt4NwOI",
        "colab_type": "text"
      },
      "source": [
        "we are removing standard hours as it is a constant and holds no weight in the equation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C_cXceVuNwOJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Now we see correlation\n",
        "corr=hrdf1.corr()\n",
        "corr"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "itlC2bGuNwOL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# Now heatmap \n",
        "\n",
        "plt.figure(figsize=(28,28))\n",
        "sns.heatmap((round(corr,2)),annot=True,cmap=\"Blues\")\n",
        "plt.title('heatmap', fontsize=20)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ymY1sHRkNwOO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# now we are taking the columns having maximum correlation\n",
        "hrdf1.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DI4ltPZ1RFCG",
        "colab_type": "text"
      },
      "source": [
        "# Spliting the data for trainig and testing\n",
        "\n",
        "### The data set is partioned in the ratio (75:25) with 1102 records for training and 368 records for testing.  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X6cY-utcNwOQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#split the dataset in features and target variable\n",
        "\n",
        "X= hrdf1.iloc[:,0:31]\n",
        "y = hrdf1.iloc[:,-1]\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.25,random_state=0)\n",
        "print(\"Xtrain shape:\",X_train.shape)\n",
        "print(\"Xtest shape:\",X_test.shape)\n",
        "print(\"ytrain shape:\",y_train.shape)\n",
        "print(\"ytest shape:\",y_test.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GKK2In1KNwOT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#import the class\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "#instantiate the model (using the default parameters)\n",
        "logreg=LogisticRegression()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-TNVDY6WNwOV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#fit the model with data\n",
        "logreg.fit(X_train,y_train)\n",
        "y_pred=logreg.predict(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0n8R_EiiNwOY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#import the metrics class\n",
        "from sklearn import metrics\n",
        "cnf_matrix=metrics.confusion_matrix(y_test,y_pred)\n",
        "print(cnf_matrix) #26 and 11 are incorrect predictions"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JP0EAH2ENwOa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.imshow(cnf_matrix, cmap='binary')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6aCs8dXtNwOf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sns.set(font_scale=1.3)#for label size\n",
        "sns.heatmap(pd.DataFrame(cnf_matrix), annot=True, cmap=\"YlGnBu\",fmt='g')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e3nRU6wRNwOl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "LogReg=LogisticRegression()\n",
        "LogReg.fit(X,y)\n",
        "print(\"Score \",LogReg.score(X,y))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c_odALnKNwOq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Accuracy\n",
        "print(\"Accuracy:\",metrics.accuracy_score(y_test,y_pred))\n",
        "print(\"Precision:\",metrics.precision_score(y_test,y_pred))\n",
        "print(\"Recall:\",metrics.recall_score(y_test,y_pred))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nM38hwmMSg6G",
        "colab_type": "text"
      },
      "source": [
        "# From confusion matrix the model accuracy has been observed as 87%"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MAcG5WuYNwOt",
        "colab_type": "text"
      },
      "source": [
        "# Classification Report"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LPrhlcQ6NwOw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "478\n",
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(y_test,y_pred))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gscDPbJyNwO1",
        "colab_type": "text"
      },
      "source": [
        "# ROC (Recievers Operating Characteristic Curve)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5_vfKTZqNwO4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_pred_proba=logreg.predict_proba(X_test)[::,1]\n",
        "fpr,tpr,_=metrics.roc_curve(y_test, y_pred_proba)\n",
        "auc=metrics.roc_auc_score(y_test,y_pred_proba)\n",
        "plt.plot(fpr,tpr,label=\"data 1,auc=\"+str(auc))\n",
        "plt.plot([0,1],[0,1],'k--')\n",
        "plt.legend(loc=1)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kY7NUnKxS1fU",
        "colab_type": "text"
      },
      "source": [
        "# ROC curve is able to define the model at 0.6% of the data for good classification. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E8XiP4jENwO8",
        "colab_type": "text"
      },
      "source": [
        "# Cross Validation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lZGbxr5uNwO9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "clf = LogisticRegression()\n",
        "scores = cross_val_score(clf, X_test, y_test, cv=10)\n",
        "print(\"10 fold Cross validation Scores \")    \n",
        "for i in scores:\n",
        "    print(i)\n",
        "print(\"\\n\")\n",
        "#mean of cross-validation\n",
        "print(\"Scores\",np.mean(scores))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f4Gtpsa9TKp_",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rU_7_TttTQqa",
        "colab_type": "text"
      },
      "source": [
        "#### As the accuracy changes with data considered in training and testing samples, we go for cross validation which gives us an average accuracy of the overall model. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MiDPZ2RuUFWV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}